# Bandit-Algorithms 
Some Multi-Armed Bandit Algorithms

**Best Arm Selection(debugging):**
* ActionElimination
* UCB
* LUCB

**Non-stationary Bandit:**
* Discount-UCB

**Budget-limited Bandit:**
* KUBE
